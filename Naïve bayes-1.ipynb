{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' theorem is a fundamental principle in probability theory that describes how to update probabilities of hypotheses based on new evidence. It is named after the Reverend Thomas Bayes, an 18th-century British mathematician and theologian, who first formulated the theorem.\n",
    "\n",
    "Mathematically, Bayes' theorem can be expressed as:\n",
    "\n",
    "**P(A∣B)= P(B∣A)×P(A) / P(B)**\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A∣B) is the probability of event A occurring given that event B has occurred (the posterior probability).\n",
    "\n",
    "P(B∣A) is the probability of event B occurring given that event A has occurred (the likelihood).\n",
    "\n",
    "P(A) and P(B) are the probabilities of events A and B occurring independently of each other (the prior probabilities of A and B).\n",
    "​\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, Bayes' theorem can be expressed as:\n",
    "\n",
    "**P(A∣B)= P(B∣A)×P(A) / P(B)**\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A∣B) is the probability of event A occurring given that event B has occurred (the posterior probability).\n",
    "\n",
    "P(B∣A) is the probability of event B occurring given that event A has occurred (the likelihood).\n",
    "\n",
    "P(A) and P(B) are the probabilities of events A and B occurring independently of each other (the prior probabilities of A and B).\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Medical Diagnosis:** Bayes' theorem is used in medical diagnosis to assess the probability of a patient having a particular disease given certain symptoms. Doctors can update their initial beliefs about the likelihood of a disease based on test results and other relevant information.\n",
    "\n",
    "**Spam Filtering:** Email spam filters often use Bayesian techniques to classify incoming emails as either spam or legitimate. By analyzing the words and patterns in emails, the filter can update its probability estimates of whether an email is spam or not.\n",
    "\n",
    "**Machine Learning:** Bayes' theorem serves as the foundation for Bayesian methods in machine learning. Bayesian models can incorporate prior knowledge about the data and update their beliefs as they receive new information, making them particularly useful for tasks like classification, regression, and clustering.\n",
    "\n",
    "**Risk Assessment:** Bayes' theorem is used in risk assessment to estimate the likelihood of certain events or outcomes occurring based on past data and other relevant factors. This is applied in various domains, including finance, insurance, and engineering.\n",
    "\n",
    "**Natural Language Processing:** Bayes' theorem is employed in various natural language processing tasks, such as language modeling, text classification, and sentiment analysis. By modeling the conditional probabilities of words or phrases given certain contexts, Bayesian methods can make accurate predictions about language-related tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' theorem establishes a connection between conditional probabilities, which are probabilities of events occurring given that other events have occurred. It essentially tells us how to update our initial beliefs (prior probabilities) about the likelihood of an event based on new evidence.\n",
    "\n",
    "In simpler terms, Bayes' theorem provides a framework for adjusting our beliefs about the probability of an event happening after considering new information. It helps us make better predictions or decisions by incorporating both our prior knowledge and the evidence at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes:**\n",
    "\n",
    "Use when the features in your dataset follow a Gaussian (normal) distribution.\n",
    "\n",
    "Suitable for continuous or real-valued features.\n",
    "\n",
    "Assumes that features are normally distributed within each class.\n",
    "\n",
    "**Multinomial Naive Bayes:**\n",
    "\n",
    "Typically used for text classification tasks where features represent word counts or frequency distributions.\n",
    "\n",
    "Well-suited for problems with discrete features that describe the occurrence of events.\n",
    "\n",
    "**Bernoulli Naive Bayes:**\n",
    "\n",
    "Appropriate for binary or categorical features, where each feature represents the presence or absence of a particular characteristic.\n",
    "\n",
    "Often used for text classification tasks with binary feature vectors (e.g., presence or absence of words in a document).\n",
    "\n",
    "**Complement Naive Bayes:**\n",
    "\n",
    "Particularly useful for imbalanced datasets where some classes dominate over others.\n",
    "\n",
    "Works well when the distribution of features within each class is skewed or imbalanced.\n",
    "\n",
    "**Categorical Naive Bayes:**\n",
    "\n",
    "Designed for categorical features with a fixed number of discrete levels.\n",
    "\n",
    "Suitable for problems with features that can take on only a limited number of distinct values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6. Assignment:**\n",
    "\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4.\n",
    "\n",
    "The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "\n",
    "A 3 3 4 4 3 3 3\n",
    "\n",
    "B 2 2 1 2 2 2 3\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior probability of class A given X: 0.5806451612903226\n",
      "Posterior probability of class B given X: 0.41935483870967744\n"
     ]
    }
   ],
   "source": [
    "# Define the frequencies\n",
    "freq_A = {'X1=1': 3, 'X1=2': 3, 'X1=3': 4, 'X2=1': 4, 'X2=2': 3, 'X2=3': 3, 'X2=4': 3}\n",
    "freq_B = {'X1=1': 2, 'X1=2': 2, 'X1=3': 1, 'X2=1': 2, 'X2=2': 2, 'X2=3': 2, 'X2=4': 3}\n",
    "\n",
    "# Prior probabilities\n",
    "P_A = 0.5\n",
    "P_B = 0.5\n",
    "\n",
    "# Likelihoods\n",
    "P_X1_3_given_A = freq_A['X1=3'] / sum(freq_A[key] for key in freq_A if 'X1=' in key)\n",
    "P_X2_4_given_A = freq_A['X2=4'] / sum(freq_A[key] for key in freq_A if 'X2=' in key)\n",
    "\n",
    "P_X1_3_given_B = freq_B['X1=3'] / sum(freq_B[key] for key in freq_B if 'X1=' in key)\n",
    "P_X2_4_given_B = freq_B['X2=4'] / sum(freq_B[key] for key in freq_B if 'X2=' in key)\n",
    "\n",
    "# Marginal probability\n",
    "P_X = (P_X1_3_given_A * P_X2_4_given_A * P_A) + (P_X1_3_given_B * P_X2_4_given_B * P_B)\n",
    "\n",
    "# Posterior probabilities\n",
    "P_A_given_X = (P_X1_3_given_A * P_X2_4_given_A * P_A) / P_X\n",
    "P_B_given_X = (P_X1_3_given_B * P_X2_4_given_B * P_B) / P_X\n",
    "\n",
    "print(\"Posterior probability of class A given X:\", P_A_given_X)\n",
    "print(\"Posterior probability of class B given X:\", P_B_given_X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
